{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emoji_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZIKes3T51veeR1k_rxpHsWCqwm2JBZJ-",
      "authorship_tag": "ABX9TyOUDROe8+Nu8Bc+GeDEI0Og",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varun-sirpal10/emoji-predictor/blob/master/Emoji_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv2odb9MCuRh",
        "colab_type": "code",
        "outputId": "a063b2e0-e546-4d0d-ab9f-80046962bcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 2.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=f44eb04294964eace08794b630c81a89a2d5e6b8703c03fc112f37942bf8d55d\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQUUcvpLC2F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import emoji"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZUU7kALDD6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emoji_dictionary = {\"0\":\"\\u2764\\uFE0F\",\n",
        "                   \"1\":\":baseball:\",\n",
        "                   \"2\":\":grinning_face_with_big_eyes:\",\n",
        "                   \"3\":\":disappointed_face:\",\n",
        "                   \"4\":\":fork_and_knife:\",\n",
        "                   \"5\":\":hundred_points:\",\n",
        "                   \"6\":\":fire:\",\n",
        "                   \"7\":\":face_blowing_a_kiss:\",\n",
        "                   \"8\":\":chestnut:\",\n",
        "                   \"9\":\":flexed_biceps:\"\n",
        "                   }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q60RahDDF8T",
        "colab_type": "code",
        "outputId": "060304de-ebcf-4396-b912-562d9b427033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "for e in emoji_dictionary.values():\n",
        "    print(emoji.emojize(e))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚ù§Ô∏è\n",
            "‚öæ\n",
            "üòÉ\n",
            "üòû\n",
            "üç¥\n",
            "üíØ\n",
            "üî•\n",
            "üòò\n",
            "üå∞\n",
            "üí™\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKwf0wxcDIS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HQSRahqDKp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"drive/My Drive/train_emoji.csv\",header=None)\n",
        "test = pd.read_csv(\"drive/My Drive/test_emoji.csv\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avEBng5IDM4n",
        "colab_type": "code",
        "outputId": "0f13762a-cd63-4809-da86-f280caed8d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head(n=5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>never talk to me again</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am proud of your achievements</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It is the worst day in my life</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Miss you so much</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>food is life</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 0  1   2     3\n",
              "0           never talk to me again  3 NaN   NaN\n",
              "1  I am proud of your achievements  2 NaN   NaN\n",
              "2   It is the worst day in my life  3 NaN   NaN\n",
              "3                 Miss you so much  0 NaN   [0]\n",
              "4                     food is life  4 NaN   NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ELT9-UPDaQR",
        "colab_type": "code",
        "outputId": "0eade233-790f-44d5-8818-cb0baa64ae26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = train.values\n",
        "print(data.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(132, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-YZUeTTDdBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train[0]\n",
        "Y_train = train[1]\n",
        "\n",
        "X_test = test[0]\n",
        "Y_test = test[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Q8Y-7JDfMu",
        "colab_type": "code",
        "outputId": "78e0c705-7547-45a4-e954-bad6391f9e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(X_train[i],emoji.emojize(emoji_dictionary[str(Y_train[i])]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "never talk to me again üòû\n",
            "I am proud of your achievements üòÉ\n",
            "It is the worst day in my life üòû\n",
            "Miss you so much ‚ù§Ô∏è\n",
            "food is life üç¥\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIUpmkjWDhnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('glove.6B.50d.txt',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1_zqwA0LR2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:],dtype='float')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alliOaPOLTxb",
        "colab_type": "code",
        "outputId": "abcb2515-7c54-4f24-9539-a8f7473e025c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_len = embeddings_index[\"eat\"].shape[0]\n",
        "print(emb_len)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw1nHQGHLX_I",
        "colab_type": "code",
        "outputId": "23f3b130-295c-4477-b8d6-3a8b5b983da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "def embedding_output(X):\n",
        "    maxLen = 10\n",
        "    embedding_out = np.zeros((X.shape[0],maxLen,emb_len))\n",
        "    \n",
        "    for ix in range(X.shape[0]):\n",
        "        X[ix] = X[ix].split()\n",
        "        for ij in range(len(X[ix])):\n",
        "            try:\n",
        "                embedding_out[ix][ij] = embeddings_index[X[ix][ij].lower()]\n",
        "            except:\n",
        "                embedding_out[ix][ij] = np.zeros((50,))\n",
        "        \n",
        "    return embedding_out\n",
        "\n",
        "embedding_matrix_train = embedding_output(X_train)\n",
        "embedding_matrix_test = embedding_output(X_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lev-Sze9La6W",
        "colab_type": "code",
        "outputId": "0230195e-b058-4fa9-a429-8575bb3ca900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132, 10, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QRrIBrKMNPh",
        "colab_type": "code",
        "outputId": "26e7a3de-e9b5-48dc-c610-1e53918dd7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix_test.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 10, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKLBIS1uMPNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "bcfd8147-2645-407d-ef87-d7e7509adda0"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import *"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BsTJc3OMmTF",
        "colab_type": "code",
        "outputId": "edcbb1c7-985a-4685-9a0d-4d92c901e9fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64,return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 10, 64)            29440     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 325       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 62,789\n",
            "Trainable params: 62,789\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBimeRCaNBWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJmY-CPYNTWt",
        "colab_type": "code",
        "outputId": "97889966-8b1e-4441-ed72-74549cd408f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "Y_train = to_categorical(Y_train,num_classes=5)\n",
        "Y_test = to_categorical(Y_test,num_classes=5)\n",
        "\n",
        "print(Y_train.shape)\n",
        "#print(Y_test.shape)\n",
        "print(Y_train[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(132, 5)\n",
            "[0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84d2gpMZNg2i",
        "colab_type": "code",
        "outputId": "0685cbcd-0773-4798-f753-76442b75768a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "#checkpoint = ModelCheckpoint(monitor='val_loss',verbose=False,save_best_only=True)\n",
        "#earlystop = EarlyStopping(patience=10,monitor='val_acc')\n",
        "\n",
        "hist = model.fit(embedding_matrix_train,Y_train,epochs=120,batch_size=64,shuffle=True,validation_split=0.2)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 27 samples\n",
            "Epoch 1/120\n",
            "105/105 [==============================] - 3s 30ms/step - loss: 1.5822 - acc: 0.2476 - val_loss: 1.6017 - val_acc: 0.2222\n",
            "Epoch 2/120\n",
            "105/105 [==============================] - 0s 595us/step - loss: 1.5631 - acc: 0.3143 - val_loss: 1.6014 - val_acc: 0.2222\n",
            "Epoch 3/120\n",
            "105/105 [==============================] - 0s 630us/step - loss: 1.5257 - acc: 0.3143 - val_loss: 1.6077 - val_acc: 0.2222\n",
            "Epoch 4/120\n",
            "105/105 [==============================] - 0s 640us/step - loss: 1.5119 - acc: 0.3810 - val_loss: 1.6191 - val_acc: 0.2222\n",
            "Epoch 5/120\n",
            "105/105 [==============================] - 0s 595us/step - loss: 1.4920 - acc: 0.4095 - val_loss: 1.6317 - val_acc: 0.2222\n",
            "Epoch 6/120\n",
            "105/105 [==============================] - 0s 621us/step - loss: 1.4557 - acc: 0.4095 - val_loss: 1.6465 - val_acc: 0.2593\n",
            "Epoch 7/120\n",
            "105/105 [==============================] - 0s 582us/step - loss: 1.4543 - acc: 0.4095 - val_loss: 1.6525 - val_acc: 0.2593\n",
            "Epoch 8/120\n",
            "105/105 [==============================] - 0s 601us/step - loss: 1.4256 - acc: 0.4476 - val_loss: 1.6514 - val_acc: 0.1481\n",
            "Epoch 9/120\n",
            "105/105 [==============================] - 0s 670us/step - loss: 1.4245 - acc: 0.4000 - val_loss: 1.6393 - val_acc: 0.1481\n",
            "Epoch 10/120\n",
            "105/105 [==============================] - 0s 633us/step - loss: 1.3770 - acc: 0.4381 - val_loss: 1.6145 - val_acc: 0.1481\n",
            "Epoch 11/120\n",
            "105/105 [==============================] - 0s 613us/step - loss: 1.3528 - acc: 0.4476 - val_loss: 1.5837 - val_acc: 0.1852\n",
            "Epoch 12/120\n",
            "105/105 [==============================] - 0s 569us/step - loss: 1.3248 - acc: 0.4381 - val_loss: 1.5382 - val_acc: 0.2222\n",
            "Epoch 13/120\n",
            "105/105 [==============================] - 0s 589us/step - loss: 1.2515 - acc: 0.4952 - val_loss: 1.4877 - val_acc: 0.2222\n",
            "Epoch 14/120\n",
            "105/105 [==============================] - 0s 617us/step - loss: 1.2230 - acc: 0.5429 - val_loss: 1.4380 - val_acc: 0.2963\n",
            "Epoch 15/120\n",
            "105/105 [==============================] - 0s 604us/step - loss: 1.1627 - acc: 0.5714 - val_loss: 1.3792 - val_acc: 0.2963\n",
            "Epoch 16/120\n",
            "105/105 [==============================] - 0s 638us/step - loss: 1.1137 - acc: 0.5905 - val_loss: 1.3303 - val_acc: 0.3333\n",
            "Epoch 17/120\n",
            "105/105 [==============================] - 0s 593us/step - loss: 1.0297 - acc: 0.6381 - val_loss: 1.2965 - val_acc: 0.3333\n",
            "Epoch 18/120\n",
            "105/105 [==============================] - 0s 632us/step - loss: 0.9857 - acc: 0.6095 - val_loss: 1.2647 - val_acc: 0.3704\n",
            "Epoch 19/120\n",
            "105/105 [==============================] - 0s 573us/step - loss: 0.9443 - acc: 0.7048 - val_loss: 1.2196 - val_acc: 0.4074\n",
            "Epoch 20/120\n",
            "105/105 [==============================] - 0s 588us/step - loss: 0.8440 - acc: 0.7143 - val_loss: 1.1459 - val_acc: 0.5185\n",
            "Epoch 21/120\n",
            "105/105 [==============================] - 0s 601us/step - loss: 0.8058 - acc: 0.7619 - val_loss: 1.0822 - val_acc: 0.5556\n",
            "Epoch 22/120\n",
            "105/105 [==============================] - 0s 598us/step - loss: 0.7458 - acc: 0.7619 - val_loss: 0.9998 - val_acc: 0.5556\n",
            "Epoch 23/120\n",
            "105/105 [==============================] - 0s 579us/step - loss: 0.6751 - acc: 0.8190 - val_loss: 0.9584 - val_acc: 0.5926\n",
            "Epoch 24/120\n",
            "105/105 [==============================] - 0s 607us/step - loss: 0.5920 - acc: 0.8571 - val_loss: 0.9699 - val_acc: 0.5926\n",
            "Epoch 25/120\n",
            "105/105 [==============================] - 0s 720us/step - loss: 0.6076 - acc: 0.8286 - val_loss: 0.9539 - val_acc: 0.6296\n",
            "Epoch 26/120\n",
            "105/105 [==============================] - 0s 578us/step - loss: 0.5120 - acc: 0.8667 - val_loss: 1.0363 - val_acc: 0.5926\n",
            "Epoch 27/120\n",
            "105/105 [==============================] - 0s 541us/step - loss: 0.4488 - acc: 0.8286 - val_loss: 1.0605 - val_acc: 0.6296\n",
            "Epoch 28/120\n",
            "105/105 [==============================] - 0s 599us/step - loss: 0.4637 - acc: 0.8381 - val_loss: 1.0489 - val_acc: 0.6296\n",
            "Epoch 29/120\n",
            "105/105 [==============================] - 0s 567us/step - loss: 0.4249 - acc: 0.8571 - val_loss: 1.0310 - val_acc: 0.6296\n",
            "Epoch 30/120\n",
            "105/105 [==============================] - 0s 621us/step - loss: 0.3859 - acc: 0.8857 - val_loss: 0.9537 - val_acc: 0.6667\n",
            "Epoch 31/120\n",
            "105/105 [==============================] - 0s 636us/step - loss: 0.3471 - acc: 0.8952 - val_loss: 0.9871 - val_acc: 0.5926\n",
            "Epoch 32/120\n",
            "105/105 [==============================] - 0s 641us/step - loss: 0.3685 - acc: 0.8667 - val_loss: 0.9727 - val_acc: 0.6296\n",
            "Epoch 33/120\n",
            "105/105 [==============================] - 0s 584us/step - loss: 0.3220 - acc: 0.8952 - val_loss: 1.0118 - val_acc: 0.6667\n",
            "Epoch 34/120\n",
            "105/105 [==============================] - 0s 609us/step - loss: 0.2716 - acc: 0.9238 - val_loss: 1.1290 - val_acc: 0.7407\n",
            "Epoch 35/120\n",
            "105/105 [==============================] - 0s 570us/step - loss: 0.2773 - acc: 0.8857 - val_loss: 1.2107 - val_acc: 0.7407\n",
            "Epoch 36/120\n",
            "105/105 [==============================] - 0s 602us/step - loss: 0.2523 - acc: 0.9143 - val_loss: 1.1670 - val_acc: 0.6667\n",
            "Epoch 37/120\n",
            "105/105 [==============================] - 0s 603us/step - loss: 0.1838 - acc: 0.9524 - val_loss: 1.2170 - val_acc: 0.6296\n",
            "Epoch 38/120\n",
            "105/105 [==============================] - 0s 620us/step - loss: 0.2927 - acc: 0.9048 - val_loss: 1.2452 - val_acc: 0.6296\n",
            "Epoch 39/120\n",
            "105/105 [==============================] - 0s 597us/step - loss: 0.1813 - acc: 0.9524 - val_loss: 1.3804 - val_acc: 0.5926\n",
            "Epoch 40/120\n",
            "105/105 [==============================] - 0s 592us/step - loss: 0.2298 - acc: 0.9429 - val_loss: 1.2786 - val_acc: 0.7407\n",
            "Epoch 41/120\n",
            "105/105 [==============================] - 0s 614us/step - loss: 0.2712 - acc: 0.9048 - val_loss: 1.2390 - val_acc: 0.7407\n",
            "Epoch 42/120\n",
            "105/105 [==============================] - 0s 620us/step - loss: 0.1402 - acc: 0.9619 - val_loss: 1.4461 - val_acc: 0.6667\n",
            "Epoch 43/120\n",
            "105/105 [==============================] - 0s 592us/step - loss: 0.2656 - acc: 0.9143 - val_loss: 1.4342 - val_acc: 0.6667\n",
            "Epoch 44/120\n",
            "105/105 [==============================] - 0s 667us/step - loss: 0.2329 - acc: 0.9143 - val_loss: 1.1469 - val_acc: 0.7037\n",
            "Epoch 45/120\n",
            "105/105 [==============================] - 0s 630us/step - loss: 0.1467 - acc: 0.9524 - val_loss: 1.3037 - val_acc: 0.6296\n",
            "Epoch 46/120\n",
            "105/105 [==============================] - 0s 605us/step - loss: 0.3691 - acc: 0.8667 - val_loss: 1.2025 - val_acc: 0.7037\n",
            "Epoch 47/120\n",
            "105/105 [==============================] - 0s 645us/step - loss: 0.1327 - acc: 0.9619 - val_loss: 1.3139 - val_acc: 0.6667\n",
            "Epoch 48/120\n",
            "105/105 [==============================] - 0s 566us/step - loss: 0.1903 - acc: 0.9619 - val_loss: 1.3890 - val_acc: 0.6296\n",
            "Epoch 49/120\n",
            "105/105 [==============================] - 0s 598us/step - loss: 0.1499 - acc: 0.9524 - val_loss: 1.2068 - val_acc: 0.6667\n",
            "Epoch 50/120\n",
            "105/105 [==============================] - 0s 585us/step - loss: 0.0971 - acc: 0.9810 - val_loss: 1.2568 - val_acc: 0.6667\n",
            "Epoch 51/120\n",
            "105/105 [==============================] - 0s 587us/step - loss: 0.1305 - acc: 0.9524 - val_loss: 1.2852 - val_acc: 0.6667\n",
            "Epoch 52/120\n",
            "105/105 [==============================] - 0s 664us/step - loss: 0.1133 - acc: 0.9619 - val_loss: 1.1572 - val_acc: 0.7037\n",
            "Epoch 53/120\n",
            "105/105 [==============================] - 0s 576us/step - loss: 0.1312 - acc: 0.9619 - val_loss: 1.2053 - val_acc: 0.6667\n",
            "Epoch 54/120\n",
            "105/105 [==============================] - 0s 540us/step - loss: 0.0838 - acc: 0.9810 - val_loss: 1.2436 - val_acc: 0.6667\n",
            "Epoch 55/120\n",
            "105/105 [==============================] - 0s 559us/step - loss: 0.0859 - acc: 0.9905 - val_loss: 1.2237 - val_acc: 0.6667\n",
            "Epoch 56/120\n",
            "105/105 [==============================] - 0s 566us/step - loss: 0.0780 - acc: 0.9810 - val_loss: 1.2190 - val_acc: 0.6667\n",
            "Epoch 57/120\n",
            "105/105 [==============================] - 0s 568us/step - loss: 0.0539 - acc: 0.9905 - val_loss: 1.2330 - val_acc: 0.6667\n",
            "Epoch 58/120\n",
            "105/105 [==============================] - 0s 563us/step - loss: 0.0659 - acc: 0.9905 - val_loss: 1.2500 - val_acc: 0.6667\n",
            "Epoch 59/120\n",
            "105/105 [==============================] - 0s 646us/step - loss: 0.0498 - acc: 0.9905 - val_loss: 1.3336 - val_acc: 0.6667\n",
            "Epoch 60/120\n",
            "105/105 [==============================] - 0s 641us/step - loss: 0.0541 - acc: 0.9810 - val_loss: 1.4401 - val_acc: 0.6296\n",
            "Epoch 61/120\n",
            "105/105 [==============================] - 0s 566us/step - loss: 0.0426 - acc: 0.9905 - val_loss: 1.5164 - val_acc: 0.6296\n",
            "Epoch 62/120\n",
            "105/105 [==============================] - 0s 600us/step - loss: 0.0442 - acc: 1.0000 - val_loss: 1.5134 - val_acc: 0.6296\n",
            "Epoch 63/120\n",
            "105/105 [==============================] - 0s 558us/step - loss: 0.0456 - acc: 0.9905 - val_loss: 1.4716 - val_acc: 0.6667\n",
            "Epoch 64/120\n",
            "105/105 [==============================] - 0s 569us/step - loss: 0.0603 - acc: 0.9810 - val_loss: 1.3085 - val_acc: 0.6667\n",
            "Epoch 65/120\n",
            "105/105 [==============================] - 0s 571us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 1.2640 - val_acc: 0.6667\n",
            "Epoch 66/120\n",
            "105/105 [==============================] - 0s 669us/step - loss: 0.0576 - acc: 0.9810 - val_loss: 1.3540 - val_acc: 0.7037\n",
            "Epoch 67/120\n",
            "105/105 [==============================] - 0s 539us/step - loss: 0.0530 - acc: 0.9905 - val_loss: 1.3175 - val_acc: 0.6667\n",
            "Epoch 68/120\n",
            "105/105 [==============================] - 0s 586us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 1.3117 - val_acc: 0.7037\n",
            "Epoch 69/120\n",
            "105/105 [==============================] - 0s 563us/step - loss: 0.0398 - acc: 0.9905 - val_loss: 1.3208 - val_acc: 0.7037\n",
            "Epoch 70/120\n",
            "105/105 [==============================] - 0s 643us/step - loss: 0.0462 - acc: 0.9810 - val_loss: 1.5630 - val_acc: 0.6667\n",
            "Epoch 71/120\n",
            "105/105 [==============================] - 0s 652us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 1.7695 - val_acc: 0.7037\n",
            "Epoch 72/120\n",
            "105/105 [==============================] - 0s 600us/step - loss: 0.0741 - acc: 0.9810 - val_loss: 1.8377 - val_acc: 0.7037\n",
            "Epoch 73/120\n",
            "105/105 [==============================] - 0s 582us/step - loss: 0.1219 - acc: 0.9810 - val_loss: 1.7769 - val_acc: 0.6667\n",
            "Epoch 74/120\n",
            "105/105 [==============================] - 0s 605us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 1.7600 - val_acc: 0.6667\n",
            "Epoch 75/120\n",
            "105/105 [==============================] - 0s 591us/step - loss: 0.0728 - acc: 0.9810 - val_loss: 1.8377 - val_acc: 0.6667\n",
            "Epoch 76/120\n",
            "105/105 [==============================] - 0s 542us/step - loss: 0.0444 - acc: 0.9905 - val_loss: 1.7369 - val_acc: 0.7037\n",
            "Epoch 77/120\n",
            "105/105 [==============================] - 0s 553us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 1.7331 - val_acc: 0.7037\n",
            "Epoch 78/120\n",
            "105/105 [==============================] - 0s 573us/step - loss: 0.0407 - acc: 0.9905 - val_loss: 1.7965 - val_acc: 0.6667\n",
            "Epoch 79/120\n",
            "105/105 [==============================] - 0s 578us/step - loss: 0.0614 - acc: 0.9810 - val_loss: 1.6800 - val_acc: 0.7037\n",
            "Epoch 80/120\n",
            "105/105 [==============================] - 0s 562us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 1.6689 - val_acc: 0.6667\n",
            "Epoch 81/120\n",
            "105/105 [==============================] - 0s 614us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 1.7354 - val_acc: 0.6667\n",
            "Epoch 82/120\n",
            "105/105 [==============================] - 0s 610us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 1.7366 - val_acc: 0.6667\n",
            "Epoch 83/120\n",
            "105/105 [==============================] - 0s 666us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 1.8037 - val_acc: 0.6667\n",
            "Epoch 84/120\n",
            "105/105 [==============================] - 0s 579us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 1.8638 - val_acc: 0.6667\n",
            "Epoch 85/120\n",
            "105/105 [==============================] - 0s 610us/step - loss: 0.0503 - acc: 0.9905 - val_loss: 1.9168 - val_acc: 0.6667\n",
            "Epoch 86/120\n",
            "105/105 [==============================] - 0s 574us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 1.9302 - val_acc: 0.6667\n",
            "Epoch 87/120\n",
            "105/105 [==============================] - 0s 605us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 1.8587 - val_acc: 0.6667\n",
            "Epoch 88/120\n",
            "105/105 [==============================] - 0s 581us/step - loss: 0.0344 - acc: 0.9905 - val_loss: 1.7350 - val_acc: 0.6667\n",
            "Epoch 89/120\n",
            "105/105 [==============================] - 0s 565us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.7034 - val_acc: 0.6667\n",
            "Epoch 90/120\n",
            "105/105 [==============================] - 0s 552us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 1.6906 - val_acc: 0.6667\n",
            "Epoch 91/120\n",
            "105/105 [==============================] - 0s 547us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 1.7908 - val_acc: 0.6667\n",
            "Epoch 92/120\n",
            "105/105 [==============================] - 0s 597us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.7446 - val_acc: 0.6667\n",
            "Epoch 93/120\n",
            "105/105 [==============================] - 0s 642us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 1.7131 - val_acc: 0.6667\n",
            "Epoch 94/120\n",
            "105/105 [==============================] - 0s 726us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.7059 - val_acc: 0.6667\n",
            "Epoch 95/120\n",
            "105/105 [==============================] - 0s 632us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 1.7202 - val_acc: 0.6667\n",
            "Epoch 96/120\n",
            "105/105 [==============================] - 0s 616us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 1.6180 - val_acc: 0.6667\n",
            "Epoch 97/120\n",
            "105/105 [==============================] - 0s 567us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.5671 - val_acc: 0.6667\n",
            "Epoch 98/120\n",
            "105/105 [==============================] - 0s 562us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.5948 - val_acc: 0.6667\n",
            "Epoch 99/120\n",
            "105/105 [==============================] - 0s 845us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.6729 - val_acc: 0.6667\n",
            "Epoch 100/120\n",
            "105/105 [==============================] - 0s 532us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 1.7505 - val_acc: 0.7037\n",
            "Epoch 101/120\n",
            "105/105 [==============================] - 0s 591us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.7942 - val_acc: 0.7037\n",
            "Epoch 102/120\n",
            "105/105 [==============================] - 0s 640us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.8111 - val_acc: 0.7037\n",
            "Epoch 103/120\n",
            "105/105 [==============================] - 0s 571us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.8277 - val_acc: 0.7037\n",
            "Epoch 104/120\n",
            "105/105 [==============================] - 0s 569us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 1.8536 - val_acc: 0.6667\n",
            "Epoch 105/120\n",
            "105/105 [==============================] - 0s 564us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 1.8734 - val_acc: 0.6667\n",
            "Epoch 106/120\n",
            "105/105 [==============================] - 0s 564us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.8526 - val_acc: 0.6667\n",
            "Epoch 107/120\n",
            "105/105 [==============================] - 0s 578us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 1.8305 - val_acc: 0.6667\n",
            "Epoch 108/120\n",
            "105/105 [==============================] - 0s 575us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.8032 - val_acc: 0.6667\n",
            "Epoch 109/120\n",
            "105/105 [==============================] - 0s 617us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.8109 - val_acc: 0.6667\n",
            "Epoch 110/120\n",
            "105/105 [==============================] - 0s 570us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.8457 - val_acc: 0.6296\n",
            "Epoch 111/120\n",
            "105/105 [==============================] - 0s 571us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 1.8911 - val_acc: 0.6296\n",
            "Epoch 112/120\n",
            "105/105 [==============================] - 0s 560us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 1.9113 - val_acc: 0.6296\n",
            "Epoch 113/120\n",
            "105/105 [==============================] - 0s 571us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.9008 - val_acc: 0.6296\n",
            "Epoch 114/120\n",
            "105/105 [==============================] - 0s 622us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 1.8730 - val_acc: 0.6296\n",
            "Epoch 115/120\n",
            "105/105 [==============================] - 0s 625us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.8474 - val_acc: 0.6296\n",
            "Epoch 116/120\n",
            "105/105 [==============================] - 0s 644us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.8344 - val_acc: 0.6296\n",
            "Epoch 117/120\n",
            "105/105 [==============================] - 0s 647us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.8438 - val_acc: 0.6667\n",
            "Epoch 118/120\n",
            "105/105 [==============================] - 0s 714us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.9018 - val_acc: 0.6667\n",
            "Epoch 119/120\n",
            "105/105 [==============================] - 0s 637us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.9726 - val_acc: 0.6667\n",
            "Epoch 120/120\n",
            "105/105 [==============================] - 0s 603us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.0299 - val_acc: 0.6667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNMYN9EfOBue",
        "colab_type": "code",
        "outputId": "3cc68bd8-8695-4424-bc6c-dcf01d62bdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pred = model.predict_classes(embedding_matrix_test)\n",
        "print(pred)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 3 2 0 2 2 1 2 2 2 1 2 3 0 1 3 2 2 3 2 0 0 4 2 3 1 2 0 1 2 0 1 3 2 0 1 2\n",
            " 3 2 2 2 0 0 1 2 3 3 2 2 1 3 0 3 2 3 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl0OZoi4QOMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"best_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol1fv97nRTPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"my_best_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bglVHglKPAMx",
        "colab_type": "code",
        "outputId": "4c6eba58-787e-45a5-fca7-6eb19455532a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(embedding_matrix_test,Y_test)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 0s 332us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.246293272290911, 0.6071428656578064]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFuDNWCKPH5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_classes(embedding_matrix_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbDAM42jymBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2348522-f729-4c96-dca3-e04a91401b4e"
      },
      "source": [
        "for i in range(30):\n",
        "  print(' '.join(X_test[i]))\n",
        "  print(emoji.emojize(emoji_dictionary[str(np.argmax(Y_test[i]))]))\n",
        "  print(emoji.emojize(emoji_dictionary[str(pred[i])]))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I want to eat\n",
            "üç¥\n",
            "üç¥\n",
            "he did not answer\n",
            "üòû\n",
            "üòû\n",
            "he got a raise\n",
            "üòÉ\n",
            "üòÉ\n",
            "she got me a present\n",
            "‚ù§Ô∏è\n",
            "‚ù§Ô∏è\n",
            "ha ha ha it was so funny\n",
            "üòÉ\n",
            "üòÉ\n",
            "he is a good friend\n",
            "‚ù§Ô∏è\n",
            "üòÉ\n",
            "I am upset\n",
            "‚ù§Ô∏è\n",
            "‚öæ\n",
            "We had such a lovely dinner tonight\n",
            "‚ù§Ô∏è\n",
            "üòÉ\n",
            "where is the food\n",
            "üç¥\n",
            "üòÉ\n",
            "Stop making this joke ha ha ha\n",
            "üòÉ\n",
            "üòÉ\n",
            "where is the ball\n",
            "‚öæ\n",
            "‚öæ\n",
            "work is hard\n",
            "üòû\n",
            "üòÉ\n",
            "This girl is messing with me\n",
            "üòû\n",
            "üòû\n",
            "are you serious ha ha\n",
            "üòÉ\n",
            "‚ù§Ô∏è\n",
            "Let us go play baseball\n",
            "‚öæ\n",
            "‚öæ\n",
            "This stupid grader is not working\n",
            "üòû\n",
            "üòû\n",
            "work is horrible\n",
            "üòû\n",
            "üòÉ\n",
            "Congratulation for having a baby\n",
            "üòÉ\n",
            "üòÉ\n",
            "stop messing around\n",
            "üòû\n",
            "üòû\n",
            "any suggestions for dinner\n",
            "üç¥\n",
            "üòÉ\n",
            "I love taking breaks\n",
            "‚ù§Ô∏è\n",
            "‚ù§Ô∏è\n",
            "you brighten my day\n",
            "üòÉ\n",
            "‚ù§Ô∏è\n",
            "I boiled rice\n",
            "üç¥\n",
            "üç¥\n",
            "she is a bully\n",
            "üòû\n",
            "üòÉ\n",
            "Why are you feeling bad\n",
            "üòû\n",
            "üòû\n",
            "I am upset\n",
            "üòû\n",
            "‚öæ\n",
            "I worked during my birthday\n",
            "üòû\n",
            "üòÉ\n",
            "My grandmother is the love of my life\n",
            "‚ù§Ô∏è\n",
            "‚ù§Ô∏è\n",
            "enjoy your break\n",
            "üòÉ\n",
            "‚öæ\n",
            "valentine day is near\n",
            "‚ù§Ô∏è\n",
            "üòÉ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N11m1a_vzKDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}